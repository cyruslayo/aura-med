{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü©∫ Aura-Med: Pediatric Respiratory Triage\n",
    "\n",
    "**Problem:** Pneumonia is the #1 infectious killer of children worldwide.  \n",
    "**Solution:** Fast, offline, audible-to-actionable triage using **HeAR** and **MedGemma**.  \n",
    "\n",
    "This notebook demonstrates the end-to-end clinical journey ‚Äî from audio input to actionable WHO IMCI treatment recommendations ‚Äî using **real model inference** on Google's Health AI Developer Foundations (HAI-DEF).\n",
    "\n",
    "### Models Used\n",
    "| Model | Role | Source |\n",
    "|---|---|---|\n",
    "| **HeAR** | Bioacoustic encoder (cough ‚Üí 512-dim embedding) | HuggingFace (`google/hear`) |\n",
    "| **MedGemma 4B-IT** | Clinical reasoning LLM (embedding + vitals ‚Üí triage) | HuggingFace (`google/medgemma-4b-it`) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Dependencies\n",
    "%pip install -q torch transformers>=4.50.0 librosa pydantic pandas psutil \\\n",
    "    tensorflow>=2.15.0 huggingface_hub bitsandbytes accelerate soundfile opendatasets\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure src/ is importable\n",
    "REPO_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if os.path.exists(os.path.join(REPO_ROOT, 'src')):\n",
    "    sys.path.insert(0, REPO_ROOT)\n",
    "elif os.path.exists(os.path.join(os.getcwd(), 'src')):\n",
    "    sys.path.insert(0, os.getcwd())\n",
    "    REPO_ROOT = os.getcwd()\n",
    "else:\n",
    "    print('‚ö†Ô∏è Could not find src/ directory. Please run from the repo root.')\n",
    "\n",
    "os.chdir(REPO_ROOT)\n",
    "print(f'Working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: HuggingFace Authentication (for gated MedGemma model)\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Option A: Set your token directly (for quick testing)\n",
    "# login(token='hf_YOUR_TOKEN_HERE')\n",
    "\n",
    "# Option B: Use Colab secrets (recommended for submission)\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    hf_token = userdata.get('HF_TOKEN')\n",
    "    login(token=hf_token)\n",
    "    print('‚úÖ Authenticated with HuggingFace via Colab Secrets')\n",
    "except Exception:\n",
    "    print('‚ö†Ô∏è No Colab secret found. Trying cached credentials...')\n",
    "    try:\n",
    "        login()\n",
    "        print('‚úÖ Using cached HuggingFace credentials')\n",
    "    except Exception:\n",
    "        print('‚ùå No HF credentials. MedGemma (gated model) may fail to download.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Hardware Check & Environment\n",
    "import torch\n",
    "import psutil\n",
    "\n",
    "def check_hardware():\n",
    "    print('--- Hardware Environment ---')\n",
    "    if torch.cuda.is_available():\n",
    "        vram = torch.cuda.get_device_properties(0).total_mem / 1e9\n",
    "        print(f'‚úÖ GPU Available: {torch.cuda.get_device_name(0)} ({vram:.1f} GB VRAM)')\n",
    "        print(f'   CUDA Version: {torch.version.cuda}')\n",
    "    else:\n",
    "        print('‚ö†Ô∏è GPU Not Available ‚Äî Demo will use mock inference')\n",
    "    \n",
    "    total_ram = psutil.virtual_memory().total / (1024**3)\n",
    "    print(f'‚úÖ Total System RAM: {total_ram:.1f} GB')\n",
    "    print(f'üì¶ PyTorch: {torch.__version__}')\n",
    "\n",
    "check_hardware()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Load Real Models\n",
    "from src.agent.core import AuraMedAgent\n",
    "from src.datatypes import PatientVitals, TriageResult, TriageStatus\n",
    "from src.demo.scenarios import DemoScenarios\n",
    "from src.visualization.renderer import NotebookRenderer\n",
    "from src.utils.latency_tracker import LatencyTracker\n",
    "from src.config import IS_DEMO_MODE, HEAR_EMBEDDING_DIM, MEDGEMMA_MODEL_PATH\n",
    "\n",
    "print(f'Demo Mode: {IS_DEMO_MODE}')\n",
    "print(f'HeAR Embedding Dim: {HEAR_EMBEDDING_DIM}')\n",
    "print(f'MedGemma Model: {MEDGEMMA_MODEL_PATH}')\n",
    "print()\n",
    "\n",
    "print('üîÑ Initializing AuraMed Agent (loading models)...')\n",
    "agent = AuraMedAgent()\n",
    "renderer = NotebookRenderer()\n",
    "tracker = LatencyTracker()\n",
    "print()\n",
    "print('‚úÖ AuraMed Agent ready for inference.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üè• Part A ‚Äî Pre-configured Clinical Journeys\n",
    "\n",
    "Three clinical flows demonstrating core capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Journey 1 ‚Äî Clinical Success (Pneumonia Detection)\n",
    "print('‚ïê' * 60)\n",
    "print('JOURNEY 1: Clinical Success ‚Äî Pneumonia Triage')\n",
    "print('‚ïê' * 60)\n",
    "\n",
    "audio_path_1, vitals_1, label_1 = DemoScenarios.get_journey_1_success()\n",
    "print(f'Patient: {vitals_1.age_months} months old, RR: {vitals_1.respiratory_rate} bpm')\n",
    "print(f'Audio: {audio_path_1}')\n",
    "print()\n",
    "\n",
    "result_1 = agent.predict(audio_path_1, vitals_1)\n",
    "tracker.record(label_1, result_1)\n",
    "\n",
    "print(f'Model Reasoning: {result_1.reasoning}')\n",
    "display(renderer.render(result_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Journey 2 ‚Äî Emergency Safety Override\n",
    "print('‚ïê' * 60)\n",
    "print('JOURNEY 2: Emergency Override ‚Äî Danger Signs Detected')\n",
    "print('‚ïê' * 60)\n",
    "\n",
    "audio_path_2, vitals_2, label_2 = DemoScenarios.get_journey_2_emergency()\n",
    "print(f'Patient: {vitals_2.age_months} months old, Danger Signs: {vitals_2.danger_signs}')\n",
    "print(f'‚ö° Safety guard should intercept BEFORE model inference')\n",
    "print()\n",
    "\n",
    "result_2 = agent.predict(audio_path_2, vitals_2)\n",
    "tracker.record(label_2, result_2)\n",
    "\n",
    "print(f'Result: {result_2.reasoning}')\n",
    "display(renderer.render(result_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Journey 3 ‚Äî Audio Quality Gate (Inconclusive)\n",
    "print('‚ïê' * 60)\n",
    "print('JOURNEY 3: Inconclusive ‚Äî Low Quality Audio')\n",
    "print('‚ïê' * 60)\n",
    "\n",
    "audio_path_3, vitals_3, label_3 = DemoScenarios.get_journey_3_inconclusive()\n",
    "print(f'Patient: {vitals_3.age_months} months old, RR: {vitals_3.respiratory_rate} bpm')\n",
    "print(f'Audio: {audio_path_3} (near-silent ‚Äî should trigger quality gate)')\n",
    "print()\n",
    "\n",
    "result_3 = agent.predict(audio_path_3, vitals_3)\n",
    "tracker.record(label_3, result_3)\n",
    "\n",
    "print(f'Result: {result_3.reasoning}')\n",
    "display(renderer.render(result_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üé§ Part B ‚Äî Interactive: Upload Your Own Recording\n",
    "\n",
    "Upload a `.wav` audio recording (e.g., a cough sound) and enter patient vitals to see the full AI triage pipeline in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Upload Audio File\n",
    "from IPython.display import display, Audio, HTML\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print('üìÅ Upload a .wav audio recording (cough, breathing, etc.):')\n",
    "print('   Recommended: 16kHz mono, 2-10 seconds long')\n",
    "print()\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "if uploaded:\n",
    "    uploaded_filename = list(uploaded.keys())[0]\n",
    "    uploaded_path = os.path.join(os.getcwd(), uploaded_filename)\n",
    "    print(f'\\n‚úÖ Uploaded: {uploaded_filename} ({len(uploaded[uploaded_filename])} bytes)')\n",
    "    \n",
    "    # Play the uploaded audio\n",
    "    print('\\nüîä Preview:')\n",
    "    display(Audio(uploaded_path))\n",
    "else:\n",
    "    uploaded_path = None\n",
    "    print('‚ö†Ô∏è No file uploaded. Please upload a .wav file and re-run this cell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Enter Patient Vitals\n",
    "print('üìã Enter patient vitals for triage assessment:')\n",
    "print('‚îÄ' * 40)\n",
    "\n",
    "#@markdown ### Patient Information\n",
    "age_months = 7  #@param {type:\"integer\"}\n",
    "respiratory_rate = 52  #@param {type:\"integer\"}\n",
    "danger_signs = False  #@param {type:\"boolean\"}\n",
    "\n",
    "custom_vitals = PatientVitals(\n",
    "    age_months=age_months,\n",
    "    respiratory_rate=respiratory_rate,\n",
    "    danger_signs=danger_signs\n",
    ")\n",
    "\n",
    "# WHO IMCI respiratory rate thresholds\n",
    "if age_months < 2:\n",
    "    threshold = 60\n",
    "elif age_months < 12:\n",
    "    threshold = 50\n",
    "else:\n",
    "    threshold = 40\n",
    "\n",
    "rr_status = '‚ö†Ô∏è FAST' if respiratory_rate >= threshold else '‚úÖ Normal'\n",
    "\n",
    "print(f'  Age: {age_months} months')\n",
    "print(f'  Respiratory Rate: {respiratory_rate} bpm ({rr_status}, threshold: {threshold})')\n",
    "print(f'  Danger Signs: {\"üî¥ YES\" if danger_signs else \"üü¢ No\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Run Triage on Uploaded Audio\n",
    "print('‚ïê' * 60)\n",
    "print('INTERACTIVE JOURNEY: Your Uploaded Recording')\n",
    "print('‚ïê' * 60)\n",
    "\n",
    "if uploaded_path and os.path.exists(uploaded_path):\n",
    "    print(f'Audio: {uploaded_filename}')\n",
    "    print(f'Patient: {custom_vitals.age_months}mo, RR={custom_vitals.respiratory_rate}, '\n",
    "          f'Danger Signs={custom_vitals.danger_signs}')\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        result_custom = agent.predict(uploaded_path, custom_vitals)\n",
    "        tracker.record('Interactive: ' + uploaded_filename, result_custom)\n",
    "        \n",
    "        print(f'Model Reasoning: {result_custom.reasoning}')\n",
    "        display(renderer.render(result_custom))\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Error during triage: {e}')\n",
    "        print('   Tip: Ensure the file is a valid .wav audio file (16kHz mono recommended).')\n",
    "else:\n",
    "    print('‚ö†Ô∏è No audio file found. Please run Cell 8 first to upload a recording.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Part C ‚Äî Dataset Validation (ICBHI 2017)\n",
    "\n",
    "Validate Aura-Med against the **ICBHI 2017 Respiratory Sound Database** ‚Äî a gold-standard medical dataset with doctor-confirmed diagnoses.\n",
    "\n",
    "### Step 1: Download the dataset to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Mount Google Drive & Download ICBHI Dataset\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create dataset directory in Drive\n",
    "ICBHI_DIR = '/content/drive/MyDrive/aura-med/data/icbhi'\n",
    "os.makedirs(ICBHI_DIR, exist_ok=True)\n",
    "\n",
    "# Check if already downloaded\n",
    "audio_dir = os.path.join(ICBHI_DIR, 'audio_and_txt_files')\n",
    "diagnosis_file = os.path.join(ICBHI_DIR, 'patient_diagnosis.csv')\n",
    "\n",
    "if os.path.exists(diagnosis_file) and os.path.exists(audio_dir):\n",
    "    n_wav = len([f for f in os.listdir(audio_dir) if f.endswith('.wav')])\n",
    "    print(f'‚úÖ ICBHI dataset already downloaded! ({n_wav} audio files found)')\n",
    "    print(f'   Location: {ICBHI_DIR}')\n",
    "else:\n",
    "    print('‚¨áÔ∏è Downloading ICBHI 2017 dataset from Kaggle...')\n",
    "    print()\n",
    "    print('üìã INSTRUCTIONS:')\n",
    "    print('   You need a Kaggle account to download. Two options:')\n",
    "    print()\n",
    "    print('   OPTION A ‚Äî Automatic (Kaggle API):')\n",
    "    print('   1. Go to kaggle.com ‚Üí Your Profile ‚Üí Settings ‚Üí API ‚Üí Create New Token')\n",
    "    print('   2. Upload the kaggle.json file when prompted below')\n",
    "    print()\n",
    "    \n",
    "    # Try automatic download via opendatasets\n",
    "    try:\n",
    "        import opendatasets as od\n",
    "        od.download(\n",
    "            'https://www.kaggle.com/datasets/vbookshelf/respiratory-sound-database',\n",
    "            data_dir='/content/drive/MyDrive/aura-med/data'\n",
    "        )\n",
    "        \n",
    "        # opendatasets saves to a subfolder ‚Äî move contents to our expected path\n",
    "        kaggle_dir = '/content/drive/MyDrive/aura-med/data/respiratory-sound-database'\n",
    "        if os.path.exists(kaggle_dir):\n",
    "            import shutil\n",
    "            # Move contents into icbhi/\n",
    "            for item in os.listdir(kaggle_dir):\n",
    "                src = os.path.join(kaggle_dir, item)\n",
    "                dst = os.path.join(ICBHI_DIR, item)\n",
    "                if not os.path.exists(dst):\n",
    "                    shutil.move(src, dst)\n",
    "            print(f'\\n‚úÖ Dataset downloaded and organized at: {ICBHI_DIR}')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'\\n‚ö†Ô∏è Automatic download failed: {e}')\n",
    "        print()\n",
    "        print('   OPTION B ‚Äî Manual Download:')\n",
    "        print('   1. Go to: https://www.kaggle.com/datasets/vbookshelf/respiratory-sound-database')\n",
    "        print('   2. Click \"Download\" (sign in if needed)')\n",
    "        print('   3. Extract the ZIP file')\n",
    "        print('   4. Upload the extracted folder to Google Drive at:')\n",
    "        print(f'      {ICBHI_DIR}/')\n",
    "        print('   5. Ensure this structure exists:')\n",
    "        print(f'      {ICBHI_DIR}/audio_and_txt_files/*.wav')\n",
    "        print(f'      {ICBHI_DIR}/patient_diagnosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Load Dataset & Show Distribution\n",
    "from src.data.icbhi_loader import ICBHIDataset\n",
    "import pandas as pd\n",
    "\n",
    "ICBHI_DIR = '/content/drive/MyDrive/aura-med/data/icbhi'\n",
    "dataset = ICBHIDataset(ICBHI_DIR)\n",
    "\n",
    "# Print summary\n",
    "print(dataset.summary())\n",
    "print()\n",
    "\n",
    "# Show as a table\n",
    "counts = dataset.get_diagnosis_counts()\n",
    "df_counts = pd.DataFrame([\n",
    "    {'Diagnosis': diag, 'Audio Files': count, \n",
    "     'Expected Triage': dataset.samples_by_diagnosis and \n",
    "     ICBHIDataset.__module__ and \n",
    "     ('YELLOW' if diag in ['Pneumonia','LRTI','Bronchiolitis','COPD','Bronchiectasis','Asthma'] else 'GREEN')}\n",
    "    for diag, count in counts.items()\n",
    "])\n",
    "display(df_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Run Batch Validation\n",
    "\n",
    "Select how many samples to test and which diagnosis to focus on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Batch Validation Configuration\n",
    "#@markdown ### Validation Settings\n",
    "num_samples = 5  #@param {type:\"integer\"}\n",
    "target_diagnosis = \"Pneumonia\"  #@param [\"Pneumonia\", \"LRTI\", \"COPD\", \"URTI\", \"Healthy\", \"Bronchiectasis\", \"Bronchiolitis\", \"Asthma\", \"All\"] {allow-input: true}\n",
    "\n",
    "if target_diagnosis == 'All':\n",
    "    target_diagnosis = None\n",
    "\n",
    "print(f'Validation config: {num_samples} samples'\n",
    "      f'{\" from \" + target_diagnosis if target_diagnosis else \" (all diagnoses)\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Run Validation & Show Results\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "print('‚ïê' * 60)\n",
    "print('DATASET VALIDATION: ICBHI 2017')\n",
    "print('‚ïê' * 60)\n",
    "\n",
    "samples = dataset.get_samples(n=num_samples, diagnosis=target_diagnosis)\n",
    "print(f'Running {len(samples)} samples through AuraMed pipeline...\\n')\n",
    "\n",
    "results = []\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i, sample in enumerate(samples, 1):\n",
    "    print(f'[{i}/{len(samples)}] Patient {sample.patient_id} ‚Äî {sample.diagnosis}')\n",
    "    try:\n",
    "        result = agent.predict(sample.audio_path, sample.vitals)\n",
    "        \n",
    "        match = '‚úÖ' if result.status == sample.expected_triage else '‚ùå'\n",
    "        if result.status == sample.expected_triage:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "        results.append({\n",
    "            'Patient': sample.patient_id,\n",
    "            'Diagnosis': sample.diagnosis,\n",
    "            'Expected': sample.expected_triage.value,\n",
    "            'Predicted': result.status.value,\n",
    "            'Confidence': f'{result.confidence:.2f}',\n",
    "            'Match': match,\n",
    "            'Reasoning': result.reasoning[:80] + '...' if len(result.reasoning) > 80 else result.reasoning\n",
    "        })\n",
    "        \n",
    "        latency = result.usage_stats.get('latency_sec', 0) if result.usage_stats else 0\n",
    "        print(f'   {match} Expected: {sample.expected_triage.value}, '\n",
    "              f'Got: {result.status.value} (conf: {result.confidence:.2f}, {latency:.1f}s)')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'   ‚ö†Ô∏è Error: {e}')\n",
    "        total += 1\n",
    "        results.append({\n",
    "            'Patient': sample.patient_id,\n",
    "            'Diagnosis': sample.diagnosis,\n",
    "            'Expected': sample.expected_triage.value,\n",
    "            'Predicted': 'ERROR',\n",
    "            'Confidence': '-',\n",
    "            'Match': '‚ö†Ô∏è',\n",
    "            'Reasoning': str(e)[:80]\n",
    "        })\n",
    "\n",
    "# Summary table\n",
    "print()\n",
    "print('‚ïê' * 60)\n",
    "accuracy = (correct / total * 100) if total > 0 else 0\n",
    "print(f'ACCURACY: {correct}/{total} ({accuracy:.1f}%)')\n",
    "print('‚ïê' * 60)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Performance Telemetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Performance Telemetry Summary\n",
    "print('‚ïê' * 60)\n",
    "print('PERFORMANCE TELEMETRY')\n",
    "print('‚ïê' * 60)\n",
    "\n",
    "display(tracker.generate_summary_table())\n",
    "\n",
    "total = tracker.get_total_runtime()\n",
    "print(f'\\nTotal pipeline runtime across all journeys: {total:.3f}s')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    vram_used = torch.cuda.max_memory_allocated() / 1e9\n",
    "    print(f'Peak GPU VRAM usage: {vram_used:.2f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This demonstration shows Aura-Med's complete clinical pipeline:\n",
    "\n",
    "- **HeAR** extracts bioacoustic embeddings from cough audio (512-dim)\n",
    "- **MedGemma 4B** performs WHO IMCI-aligned clinical reasoning\n",
    "- **Safety Guard** provides rule-based override for emergency danger signs\n",
    "- **Quality Gate** rejects low-quality audio before it reaches the AI\n",
    "- **ICBHI Validation** tests accuracy against real medical diagnoses\n",
    "\n",
    "All inference runs within edge-deployment constraints (< 4 GB RAM, < 10s latency)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
