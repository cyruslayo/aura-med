{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: Hardware Check\n",
    "import torch\n",
    "\n",
    "def check_hardware():\n",
    "    if torch.cuda.is_available():\n",
    "        vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"✅ GPU Available: {torch.cuda.get_device_name(0)} ({vram:.1f} GB VRAM)\")\n",
    "    else:\n",
    "        print(\"⚠️ GPU Not Available - Logic Verification Mode Only\")\n",
    "\n",
    "check_hardware()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aura-Med: Pediatric Respiratory Triage\n",
    "\n",
    "**Problem:** Pneumonia is the #1 infectious killer of children worldwide (700,000 deaths/year).\n",
    "**Solution:** Fast, offline, audible-to-actionable triage using HeAR and MedGemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup & Dependencies\n",
    "!pip install -q torch transformers librosa pydantic\n",
    "print(\"✅ Dependencies installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration\n",
    "import os\n",
    "\n",
    "# Resource Constraints\n",
    "MAX_RAM_GB = 4.0\n",
    "MAX_INFERENCE_TIME_SEC = 10.0\n",
    "\n",
    "# Model Paths (Mock or Real)\n",
    "HEAR_MODEL_PATH = \"google/hear-encoder\"\n",
    "MEDGEMMA_MODEL_PATH = \"google/medgemma-2b\"\n",
    "\n",
    "# Audio Settings\n",
    "SAMPLE_RATE = 16000\n",
    "MAX_AUDIO_DURATION_SEC = 10\n",
    "\n",
    "# Demo Settings\n",
    "IS_DEMO_MODE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Core Components & Data Structures\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict\n",
    "from pydantic import BaseModel, Field\n",
    "class TriageStatus(str, Enum):\n",
    "    GREEN = \"GREEN\"\n",
    "    YELLOW = \"YELLOW\"\n",
    "    RED = \"RED\"\n",
    "    INCONCLUSIVE = \"INCONCLUSIVE\"\n",
    "class PatientVitals(BaseModel):\n",
    "    age_months: int = Field(..., ge=0, description=\"Patient age in months\")\n",
    "    respiratory_rate: int = Field(..., ge=0, description=\"Breaths per minute\")\n",
    "    danger_signs: bool = Field(False, description=\"Presence of any general danger signs\")\n",
    "@dataclass\n",
    "class TriageResult:\n",
    "    status: TriageStatus\n",
    "    confidence: float\n",
    "    reasoning: str\n",
    "    usage_stats: Optional[Dict[str, float]] = None\n",
    "    action_recommendation: Optional[str] = None\n",
    "class DangerSignException(Exception):\n",
    "    \"\"\"Raised when danger signs are detected, triggering immediate override.\"\"\"\n",
    "    pass\n",
    "class LowQualityError(Exception):\n",
    "    \"\"\"Raised when audio quality/duration is insufficient.\"\"\"\n",
    "    pass\n",
    "class LowConfidenceError(Exception):\n",
    "    \"\"\"Raised when model confidence is below threshold.\"\"\"\n",
    "    pass\n",
    "class EdgeConstraintViolation(Exception):\n",
    "    \"\"\"Raised when resource usage exceeds edge limits.\"\"\"\n",
    "    pass\n",
    "def load_audio(path: str, sr: int = 16000):\n",
    "    \"\"\"Load audio and resample to target rate.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Audio file not found: {path}\")\n",
    "    waveform, sample_rate = librosa.load(path, sr=sr, mono=True)\n",
    "    return waveform, sample_rate\n",
    "def normalize_duration(audio, target_length: float = 10.0, sr: int = 16000):\n",
    "    \"\"\"Truncate or zero-pad audio to target duration.\"\"\"\n",
    "    target_samples = int(target_length * sr)\n",
    "    current_samples = len(audio)\n",
    "    if current_samples > target_samples:\n",
    "        return audio[:target_samples]\n",
    "    elif current_samples < target_samples:\n",
    "        return np.concatenate((audio, np.zeros(target_samples - current_samples)))\n",
    "    return audio\n",
    "class HeAREncoder:\n",
    "    \"\"\"Implementation of HeAR Encoder pipeline (preprocessing + mock inference).\"\"\"\n",
    "    def __init__(self):\n",
    "        print(f\"Loading HeAR Encoder from {HEAR_MODEL_PATH}...\")\n",
    "    def encode(self, audio_path: str) -> torch.Tensor:\n",
    "        \"\"\"Extract embeddings after preprocessing audio.\"\"\"\n",
    "        waveform, sr = load_audio(audio_path, sr=SAMPLE_RATE)\n",
    "        if len(waveform) < sr:\n",
    "            raise LowQualityError(\"Audio recording is too short (min 1s required)\")\n",
    "        \n",
    "        normalized_waveform = normalize_duration(waveform, target_length=MAX_AUDIO_DURATION_SEC, sr=sr)\n",
    "        return torch.randn(1, 1024)\n",
    "\n",
    "\n",
    "class MedGemmaReasoning:\n",
    "    \"\"\"\n",
    "    Mock implementation of MedGemma Reasoning Engine.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the reasoning engine.\"\"\"\n",
    "        print(f\"Loading MedGemma from {MEDGEMMA_MODEL_PATH}...\")\n",
    "        pass\n",
    "\n",
    "    def generate(self, embedding, vitals: PatientVitals) -> TriageResult:\n",
    "        \"\"\"\n",
    "        Generate triage result based on embedding and vitals.\n",
    "        \n",
    "        Args:\n",
    "            embedding: HeAR embedding\n",
    "            vitals: Patient vital signs\n",
    "            \n",
    "        Returns:\n",
    "            TriageResult: Structured triage output\n",
    "        \"\"\"\n",
    "        # Mock logic\n",
    "        return TriageResult(\n",
    "            status=TriageStatus.YELLOW,\n",
    "            confidence=0.85,\n",
    "            reasoning=\"Mock reasoning: Crackles detected consistent with pneumonia.\",\n",
    "            usage_stats={\"ram_gb\": 0.5},\n",
    "            action_recommendation=\"Administer oral Amoxicillin. Follow up in 48 hours.\"\n",
    "        )\n",
    "\n",
    "# Execution Test\n",
    "print(\"✅ Code synced successfully.\")\n",
    "print(\"Initializing Mock Models...\")\n",
    "hear = HeAREncoder()\n",
    "medgemma = MedGemmaReasoning()\n",
    "print(\"✅ Mock Models Initialized\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
